---
title: Random forest model construction
author: "Dajun Wang"
date: "July 2020"
output:
  html_document:
    toc: no
    df_print: paged
  word_document:
    toc: no
  pdf_document:
    toc: no
    number_sections: yes
    fig_caption: yes
    df_print: kable
    highlight: tango
fontsize: 11pt
geometry: margin = 1.2in
bibliography: ../ch.1-lit-review/zot-library.bib
editor_options:
  chunk_output_type: console
spacing: double
mainfont: Times New Roman
header-includes:
- \setlength\parindent{24pt}
- \usepackage{indentfirst}
- \usepackage{setspace}\doublespacing
---
```{r global options, cache=FALSE, include=FALSE}
set.seed(2807)
knitr::opts_chunk$set(fig.pos = 'H') #to set all images to top
knitr::read_chunk('ch2-main.Rmd')
options(tinytex.verbose = TRUE)
```

# Introduction

# Material and methods


```{r setup, include=FALSE}
list.of.packages <- c("lubridate", "dplyr", "ggplot2","randomForest", "corrplot", "knitr", "glmm", "tinytex","xtable","ggcorrplot","stargazer","kableExtra", "captioner","formattable", "reshape2", "lme4") 

new.packages <- list.of.packages[!(list.of.packages %in% installed.packages()[,"Package"])]
if (length(new.packages)) install.packages(unlist(new.packages))
lapply(list.of.packages, require, character.only = T)

options(tibble.print_max = Inf) # To show all rows
options(tibble.width = Inf) # To show all columns; Inf controls value

knitr::opts_chunk$set(fig.width=12, fig.height=8, fig.path='Figs/',
                      echo=FALSE, warning=FALSE, message=FALSE)
```


# Materials and methods

```{r data preparation}
data = read.csv("2020-07-20_mla-train-data.csv")
data$X = NULL
data$dog = as.factor("newguys")
data = data %>%
  mutate(behaviour = annotation,
         X = acceleration.x,
         Y = acceleration.y,
         Z = acceleration.z) %>%
  select(dog, sample, burst.timestamp, sample.timestamp, X, Y, Z, behaviour)
  

train.data = read.csv("acc_randomforest-training-data03.csv")
train = rbind(train.data, data)

eat = filter(train, behaviour == "eat") 
eat$index = rep(1:(nrow(eat)/20), each = 20)
forage = filter(train, behaviour == "forage")
forage$index = rep(1:(nrow(forage)/20), each = 20)
lie = filter(train, behaviour == "lie")
lie$index = rep(1:(nrow(lie)/20), each = 20)
run = filter(train, behaviour == "run")
run$index = rep(1:(nrow(run)/20), each = 20)
sit = filter(train, behaviour == "sit")
sit$index = rep(1:(nrow(sit)/20), each = 20)
stand = filter(train, behaviour == "stand")
stand$index = rep(1:(nrow(stand)/20), each = 20)
walk = filter(train, behaviour == "walk")
walk$index = rep(1:(nrow(walk)/20), each = 20)

train.data = rbind(eat, forage, lie, run, sit, stand, walk)
```

```{r transform cleaned data}

rf.data = train.data %>%
  group_by(dog, behaviour, index)%>%
  summarize(behaviour = first(behaviour),
            mean.x = mean(X, na.rm = TRUE),
            mean.y = mean(Y, na.rm =TRUE),
            mean.z = mean(Z, na.rm = TRUE),
            min.x = min(X, na.rm = TRUE),
            min.y = min(Y, na.rm =TRUE),
            min.z = min(Z, na.rm = TRUE),
            kurt.x = kurtosis(X, na.rm = TRUE),
            kurt.y = kurtosis(Y, na.rm =TRUE),
            kurt.z = kurtosis(Z, na.rm = TRUE),
            skew.x = skewness(X, na.rm = TRUE),
            skew.y = skewness(Y, na.rm =TRUE),
            skew.z = skewness(Z, na.rm = TRUE),
            max.x = max(X, na.rm = TRUE),
            max.y = max(Y, na.rm =TRUE),
            max.z = max(Z, na.rm = TRUE),
            sd.x = sd(X, na.rm = TRUE),
            sd.y = sd(Y, na.rm =TRUE),
            sd.z = sd(Z, na.rm = TRUE),
            range.x = max.x - min.x,
            range.y = max.y - min.y,
            range.z = max.z - min.z
            )

rf.data = select(rf.data, -index)
# Write the data above

```

```{r rf model 1}
rf.data = read.csv("2020-07-20_cleaned-rf-data2.txt")
rf.data$behaviour = as.factor(rf.data$behaviour)
rf.data$dog = NULL
rf.data$X = NULL
rf.data = as.data.frame(rf.data)

g <- runif(nrow(rf.data))
rf.data <- rf.data[order(g),] 

s1 = sample(nrow(rf.data), 0.8 * nrow(rf.data)) # Take 80% subset to train data, 20% to test

rf.data_train <- rf.data[s1,]
rf.data_test <- rf.data[-s1,]

# raw2_train <- raw2.rf.re[s1,]
# raw2_test <- raw2.rf.re[-s1,]

model = randomForest(behaviour ~., data = rf.data_train, 
                        method = "class", ntree = 500, mtry = 10)
predTest = predict(model, rf.data_test, type = "class")

test.result2 = stargazer(model$confusion, type = "text", summary = F)
test.result2

#Table for model for raw 2 sec burst training data

model.df = data.frame(Behaviour = c(model$classes),
                  Error = c(model$confusion[,8]))

model.corr = data.frame(Behaviour = c(model$classes),
                  eat = c(model$confusion[,1]),
                  forage = c(model$confusion[,2]),
                  lie = c(model$confusion[,3]),
                  run = c(model$confusion[,4]),
                  sit = c(model$confusion[,5]),
                  stand = c(model$confusion[,6]),
                  walk = c(model$confusion[,7]))

model.matrix = as.matrix(model.corr[,-1], nrow = 7, ncol = 7)
model.prop.t = round(prop.table(model.matrix,1),3)
model.corr.plot = corrplot(model.prop.t,
                            type = "full",
                            order = "hclust",
                            method = "number",
                            tl.col = "black",
                            tl.srt = 45)

model.corr.plot 
#Correlation plot of the prediction accuracy of behaviours within the training dataset



model.individual.behaviour.plot = ggplot(data = model.df, 
                                          aes(x= reorder(Behaviour, +Error), y=Error)) + geom_bar(stat = "identity")

model.individual.behaviour.plot = model.individual.behaviour.plot + coord_flip()

model.individual.behaviour.plot 

importance(model)
varImpPlot(model)
#Importance of each variable for behaviour prediction accuracy

plot(model$err.rate[,1], ylab = "Out-Of-Bag Error Rate estimate", xlab = "Number of trees")
#shows the stability of the randomforest prediction after X no. of trees / importance of ntree


model.mtry = c()
i=21
for (i in 1:21) {
  model.mtry.train <- randomForest(behaviour ~ ., data = rf.data_train, ntree = 500, mtry = i, importance = TRUE)
  predTest.mtry <- predict(model.mtry.train, rf.data_test, type = "class")
  model.mtry[i] = mean(predTest.mtry == rf.data_test$behaviour)
}

model.mtry.df = data.frame(mTry = c(1:21), Accuracy = c(model.mtry))
plot(model.mtry.df)

model.mtry.df.plot = ggplot(data = model.mtry.df, 
                             aes(x = mTry, y = Accuracy )) + geom_point(stat = "identity", 
                                                                     size = 3,
                                                                     shape = "square",
                                                                     color = "red")

model.mtry.df.plot
#Prediction accuracy of randomforest model (2 second burst) with varying mtry variables

mean(predTest == rf.data_test$behaviour)
table(predTest, rf.data_test$behaviour)
#Predicting on Test results

```

# Results 

# Discussion

# Conclusion





\newpage

# References