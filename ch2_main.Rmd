---
title: "chapter 2 - RF model"
author: "Dajun Wang"
date: "7/20/2020"
output:
  pdf_document: default
  html_document: default
editor_options:
  chunk_output_type: console
---
```{r global options, cache=FALSE, include=FALSE}
set.seed(2807)
knitr::opts_chunk$set(fig.pos = 'H') #to set all images to top
knitr::read_chunk('ch2_main.Rmd')
options(tinytex.verbose = TRUE)
```

```{r setup, include=FALSE}
list.of.packages <- c("lubridate", "dplyr", "ggplot2","randomForest", "corrplot", "knitr", "glmm", "tinytex","xtable","ggcorrplot","stargazer","kableExtra", "captioner","formattable", "reshape2", "lme4") 

new.packages <- list.of.packages[!(list.of.packages %in% installed.packages()[,"Package"])]
if (length(new.packages)) install.packages(unlist(new.packages))
lapply(list.of.packages, require, character.only = T)

options(tibble.print_max = Inf) # To show all rows
options(tibble.width = Inf) # To show all columns; Inf controls value

knitr::opts_chunk$set(fig.width=12, fig.height=8, fig.path='Figs/',
                      echo=FALSE, warning=FALSE, message=FALSE)
```

```{r captioner, include = FALSE}

```

# Introduction


# Material and methods

We used wildlife tracking collars (e-obs gmbh) equipped with tri-axial accelerometers sampling continuously at 10Hz to monitor behaviour in domestic and free-roaming dogs. The wildlife tracking collar (hence tri-axial accelerometer) was mounted such that the x-, y-, and z- axes were parallel to the median (surge), the dorsal (sway), and the dorsal (heave) planes of the animal, respectively. Eleven adult dogs (of German Shepard and Golden Retriever breeds) were selected and collared to obtain the training dataset required for the construction of the random forest model. All eleven dogs were well-trained individuals that could perform the selected repertoire of movement behaviours (see Table 1 for more information) through the verbal instructions of their trainer while being off-leash. Each dog was tasked to perform the entire repertoire of behaviours at least twice (with consent from their trainer), and approximately 300 minutes of video-recorded behavioural observations were obtained.

The acceleration measurements collected from the collared dogs were binned into two-second windows (or 'bursts') and were labelled accordingly with the associated dog behaviour. Labelling was done by matching with the video footage time-stamps of the performed dog behaviour to the time-stamps of the collected acceleration measurements. All performed (and observed) dog behaviours were limited into the seven categories as described in Table 1, and behavioural transitions were not catalogued since they occurred very quickly (i.e., less than 1s). Labelled acceleration measurements were binned into two-second bursts as this duration was found to accomodate at least two full strides for motion-based dog behaviours (i.e., walking, foraging) without much influence from un-intentional behavioural transitions.

Random Forests (RF) [@Lush2016b;@Graf2015d] was selected as the modeling tool for predicting unobserved behaviours in wild animals based on measurements of observed behaviours in captive animals. Random Forests is a relatively novel and powerful machine learning algorithm that has been reported to work well with complex ecological data that are not easily fitted by traditional methods such as generalized linear models [@Cutler2007]. Random Forests are capable of making accurate predictions from datasets with highly correlated predictor variables and identify the importance measures of each conditional variable. This capability identifies the extent of which a specific predictor variable influences the algorithm's classification accuracy [@Cutler2007]; a higher measure of importance in a predictor variable demonstrates the greater influence it has in comparison to the other predictor variables used in the model [@Cutler2007].

To construct the RF model to predict the seven classes of dog behaviour (Table 2), a series of summary statistics (mean, min, max, kurtosis, skewness, range, standard deviation) for all three axes were applied onto each labelled burst of accelerometer measurements to describe the predictor variables of the random forest model. Subsequently, a range of mtry (i.e., number of predictor variables available for splitting at each tree node; different mTry parameter values can affect model sensitivity and stability) and ntree (i.e., number of decision 'trees'; larger number of trees produce more stable models) parameters were examined to identify the values that have the strongest influence on the predictive capacity of the model. Predictions made by all trees for each observation were then tallied and prediction accuracies were calculated by comparing the predicted and actual classifications. The 'randomForest' package [@Liaw2002] in the R (version 3.0.1, R Core Team 2013) statistical program was used to construct and fit all models, and to derive the variable importance estimates of each used predictor variable.

|  Statistics Label  |   Predictor Variables   |                                                Descriptions                                                |
|:------------------:|:-----------------------:|:----------------------------------------------------------------------------------------------------------:|
|        Mean        |   mean.x mean.y mean.z  | The calculated mean of the acceleration  measurements within each burst for axes x, y and z.               |
|         Min        |    min.x min.y min.z    | The smallest acceleration measurement within  each burst for axes x, y and z.                              |
|         Max        |    max.x max.y max.z    | The largest acceleration measurement within  each burst for axes x, y and z.                               |
|      Kurtosis      |   kurt.x kurt.y kurt.z  | The relative flatness of the acceleration  measurements within each burst for axes x, y and z.             |
|        Skew        |   skew.x skew.y skew.z  | The relative skewness of the acceleration  measurements within each burst for axes x, y and z.             |
|        Range       | range.x range.y range.z | The calculated difference between the largest and  smallest acceleration measurements of axes x, y, and z. |
| Standard Deviation |      sd.x sd.y sd.z     | The calculated standard deviations of the  acceleration measurements of axes x, y, and z.                  |


i used rf to find the variance of identified movement behaviours (which becomes a table) and picked an arbitrary value from an axis that best represents motion in a dog. After which, I ground-truth the acc-thr value by incorporating the desired value into a tracking collar and brought four different dogs for a walk. All dogs were walked continuously for approximately ten minutes, and with the studied dog resting (with the collar on) only in the beginning and end of each walk. The dogs were rested in a non-motion movement behaviour (e.g., lying, sitting or standing) to simulate the resting behaviour of free-roaming dogs in the wild. The GPS and ACC dataset were then retrieved from the collar, and the occurence of short- and long-burst gps relocations were plotted sequentially against the variance of the accelerometer measurements collected from all three axes. 

test test

```{r rf data preparation, eval=FALSE, include=FALSE}
data = read.csv("2020-07-20_mla-train-data.csv")
data$X = NULL
data$dog = as.factor("newguys")
data = data %>%
  mutate(behaviour = annotation,
         X = acceleration.x,
         Y = acceleration.y,
         Z = acceleration.z) %>%
  select(dog, sample, burst.timestamp, sample.timestamp, X, Y, Z, behaviour)
  

train.data = read.csv("acc_randomforest-training-data03.csv")
train = rbind(train.data, data)

eat = filter(train, behaviour == "eat") 
eat$index = rep(1:(nrow(eat)/20), each = 20)
forage = filter(train, behaviour == "forage")
forage$index = rep(1:(nrow(forage)/20), each = 20)
lie = filter(train, behaviour == "lie")
lie$index = rep(1:(nrow(lie)/20), each = 20)
run = filter(train, behaviour == "run")
run$index = rep(1:(nrow(run)/20), each = 20)
sit = filter(train, behaviour == "sit")
sit$index = rep(1:(nrow(sit)/20), each = 20)
stand = filter(train, behaviour == "stand")
stand$index = rep(1:(nrow(stand)/20), each = 20)
walk = filter(train, behaviour == "walk")
walk$index = rep(1:(nrow(walk)/20), each = 20)

train.data = rbind(eat, forage, lie, run, sit, stand, walk)
```

```{r transforming data, eval=FALSE, include=FALSE}

rf.data = train.data %>%
  group_by(dog, behaviour, index)%>%
  summarize(behaviour = first(behaviour),
            mean.x = mean(X, na.rm = TRUE),
            mean.y = mean(Y, na.rm =TRUE),
            mean.z = mean(Z, na.rm = TRUE),
            min.x = min(X, na.rm = TRUE),
            min.y = min(Y, na.rm =TRUE),
            min.z = min(Z, na.rm = TRUE),
            kurt.x = kurtosis(X, na.rm = TRUE),
            kurt.y = kurtosis(Y, na.rm =TRUE),
            kurt.z = kurtosis(Z, na.rm = TRUE),
            skew.x = skewness(X, na.rm = TRUE),
            skew.y = skewness(Y, na.rm =TRUE),
            skew.z = skewness(Z, na.rm = TRUE),
            max.x = max(X, na.rm = TRUE),
            max.y = max(Y, na.rm =TRUE),
            max.z = max(Z, na.rm = TRUE),
            sd.x = sd(X, na.rm = TRUE),
            sd.y = sd(Y, na.rm =TRUE),
            sd.z = sd(Z, na.rm = TRUE),
            range.x = max.x - min.x,
            range.y = max.y - min.y,
            range.z = max.z - min.z
            )

rf.data = select(rf.data, -index)
# Write the data above

```


```{r s.s table, eval = FALSE, results = 'asis'}


```


```{r rf model preparation, include = FALSE}
rf.data = read.csv("2020-07-20_cleaned-rf-data2.txt") # data file prep'n described above
rf.data$behaviour = as.factor(rf.data$behaviour)
rf.data$dog = NULL
rf.data$X = NULL
rf.data = as.data.frame(rf.data)

g <- runif(nrow(rf.data))
rf.data <- rf.data[order(g),] 

s1 = sample(nrow(rf.data), 0.80 * nrow(rf.data)) # Take 90% subset to train data, 10% to test

rf.data_train <- rf.data[s1,] # randomize the order of the training dataset
rf.data_test <- rf.data[-s1,] # and the testing dataset

```

```{r mtry code}
set.seed(2807)
model.mtry = c() # Do 'mtry' loop to identify best value for mtry
i=21
for (i in 1:21) {
  model.mtry.train <- randomForest(behaviour ~ ., data = rf.data_train, ntree = 500, mtry = i, importance = TRUE)
  predTest.mtry <- predict(model.mtry.train, rf.data_test, type = "class")
  model.mtry[i] = mean(predTest.mtry == rf.data_test$behaviour)
}

model.mtry.df = data.frame(mTry = c(1:21), Accuracy = c(model.mtry))
best.mtry = model.mtry.df %>%
  arrange(desc(Accuracy)) %>%
  slice(1)

best.mtry = best.mtry$mTry

(model.mtry.df.plot = ggplot(data = model.mtry.df, 
                             aes(x = mTry, y = Accuracy )) + geom_point(stat = "identity", 
                                                                     size = 3,
                                                                     shape = "square",
                                                                     color = "red"))


```


```{r mtry plot}
#model.mtry.df.plot
#Prediction accuracy of randomforest model (2 second burst) with varying mtry variables
# most optimum value is 16
```


```{r rf model construction}
set.seed(2807)
model = randomForest(behaviour ~., data = rf.data_train, 
                        method = "class", ntree = 500, mtry = 15)
predTest = predict(model, rf.data_test, type = "class")

```

```{r rf model prediction inaccuracy}
# stargazer(model$confusion, type = "text", summary = F)
orig = as.data.frame(model$confusion[,1:7])
orig$accuracy = percent(1-model$confusion[,8])
stargazer(orig, type = 'text', summary = F)

#Table for model for raw 2 sec burst training data
```

```{r refining the rf model}
model.df = data.frame(Behaviour = c(model$classes),
                  Error = c(model$confusion[,8]))
# 
# model.corr = data.frame(Behaviour = c(model$classes),
#                   eat = c(model$confusion[,1]),
#                   forage = c(model$confusion[,2]),
#                   lie = c(model$confusion[,3]),
#                   run = c(model$confusion[,4]),
#                   sit = c(model$confusion[,5]),
#                   stand = c(model$confusion[,6]),
#                   walk = c(model$confusion[,7]))
# 
# model.matrix = as.matrix(model.corr[,-1], nrow = 7, ncol = 7)
# model.prop.t = round(prop.table(model.matrix,1),3)
# model.corr.plot = corrplot(model.prop.t,
#                             type = "full",
#                             order = "hclust",
#                             method = "number",
#                             tl.col = "black",
#                             tl.srt = 45)
#Correlation plot of the prediction accuracy of behaviours within the training dataset
# A repeat of information, feels slightly unnecessary


model.individual.behaviour.plot = ggplot(data = model.df, 
                                          aes(x= reorder(Behaviour, +Error), y=Error)) + geom_bar(stat = "identity")

model.individual.behaviour.plot = model.individual.behaviour.plot + coord_flip()

model.individual.behaviour.plot 
```

``` {r variable importance}
#importance(model)
varImpPlot(model)
#Importance of each variable for behaviour prediction accuracy

```

```{r ntree out-of-bag error}
plot(model$err.rate[,1], ylab = "Out-Of-Bag Error Rate estimate", xlab = "Number of trees")
#shows the stability of the randomforest prediction after X no. of trees / importance of ntree
```

``` {r rf results}
x = table(predTest, rf.data_test$behaviour)
z = as.data.frame.matrix(x) # 

accuracy = vector()
for (i in 1:nrow(z)) {

  accuracy[i] = max(z[i])/sum(z[i])
}

z = rbind(z, accuracy)
zt = t(z)
zt = as.data.frame(zt)
zt$accuracy = percent(zt$"8")
zt = zt %>% dplyr::select(eat, forage, lie, run, sit, stand, walk, accuracy)

# Prediction accuracy based on test data set

percent(mean(predTest == rf.data_test$behaviour))
```

```{r reading acc-thr data}
df = read.csv("2020-07-20_mla-train-data.csv")
df$X = NULL
df$dog = as.factor("newguys")
data = df %>%
  mutate(behaviour = annotation,
         X = acceleration.x,
         Y = acceleration.y,
         Z = acceleration.z) %>%
  select(dog, sample, burst.timestamp, sample.timestamp, X, Y, Z, behaviour)
df2 = read.csv("acc_randomforest-training-data03.csv")
df = rbind(data, df2)
df = tbl_df(df)
df$behaviour = as.factor(df$behaviour)

walk = subset(df, df$behaviour == "walk")
run = subset(df, df$behaviour == "run")
lie = subset(df, df$behaviour == "lie")
sit = subset(df, df$behaviour == "sit")
stand = subset(df, df$behaviour == "stand")
forage = subset(df, df$behaviour == "forage")
eat = subset(df, df$behaviour == "eat")

move = rbind(walk, run, forage)
still = rbind (lie, sit, stand)

```

```{r choosing variance values for behaviours}
walk = walk[1:(round(nrow(walk)/26)*26),]
walk$index = rep(1:(nrow(walk)/26), each = 26)

walk.var = walk %>%
  group_by(dog,index) %>%
  summarise(var.x = var(X),
            var.y = var(Y),
            var.z = var(Z)) %>%
  mutate(behaviour = "walk")

run = run[1:(round(nrow(run)/26)*26),]
run$index = rep(1:(nrow(run)/26), each = 26)

run.var = run %>%
  group_by(dog,index) %>%
  summarise(var.x = var(X),
            var.y = var(Y),
            var.z = var(Z)) %>%
  mutate(behaviour = "run")

forage = forage[1:(round(nrow(forage)/26)*26),]
forage$index = rep(1:(nrow(forage)/26), each = 26)

forage.var = forage %>%
  group_by(dog,index) %>%
  summarise(var.x = var(X),
            var.y = var(Y),
            var.z = var(Z)) %>%
  mutate(behaviour = "forage")

lie = lie[1:(round(nrow(lie)/26)*26),]
lie$index = rep(1:(nrow(lie)/26), each = 26)

lie.var = lie %>%
  group_by(dog,index) %>%
  summarise(var.x = var(X),
            var.y = var(Y),
            var.z = var(Z)) %>%
  mutate(behaviour = "lie")


sit = sit[1:(round(nrow(sit)/26)*26),]
sit$index = rep(1:(nrow(sit)/26), each = 26)

sit.var = sit %>%
  group_by(dog,index) %>%
  summarise(var.x = var(X),
            var.y = var(Y),
            var.z = var(Z)) %>%
  mutate(behaviour = "sit")


stand = stand[1:(round(nrow(stand)/26)*26),]
stand$index = rep(1:(nrow(stand)/26), each = 26)

stand.var = stand %>%
  group_by(dog,index) %>%
  summarise(var.x = var(X),
            var.y = var(Y),
            var.z = var(Z)) %>%
  mutate(behaviour = "stand")
```

```{r visualizing chosen variance values}
move = rbind(walk.var, run.var, forage.var)
move = na.omit(move)
move$behavior = as.factor(move$behaviour)


still = rbind(lie.var, sit.var, stand.var)
still = na.omit(still)
still$behaviour = as.factor(still$behaviour)

df.all = rbind(run.var, forage.var, walk.var, stand.var, sit.var, lie.var)
df.all = na.omit(df.all)
df.all$behaviour = as.factor(df.all$behaviour)

all.variance.table = df.all %>% # The greatest difference between variance values are in axis Z
  group_by(behaviour) %>%
  summarise(mean.X = mean(var.x),
            mean.Y = mean(var.y),
            mean.Z = mean(var.z)) %>%
  arrange(mean.Z)

```


```{r ground truthing the acc-thr value}
match = read.csv('2020-07-21_acc-thr_gps-cleaned.csv') # manual-cleaned gps data
match$burst = match$X

ggplot(match, aes(x = burst)) +
  geom_line(aes(y = var.x), color = 'red') + 
  geom_line(aes(y = var.y), color = 'green') + 
  geom_line(aes(y = var.z), color = 'blue') + 
  geom_point(aes(y = time.diff3*50000), color = 'black')

# Set acc-thr as decided in above section in the gps collar, and 
#took 4 different dogs for a walk with a planned route.
```

# Results 

# Discussion

# Conclusion





\newpage

# References